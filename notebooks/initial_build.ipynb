{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://data.ny.gov/Transportation/MTA-Subway-Hourly-Ridership-Beginning-February-202/wujg-7c2s/about_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dec_prec(row):\n",
    "    latitude = row[\"latitude\"]\n",
    "    longitude = row[\"longitude\"]\n",
    "    # Assuming latitude and longitude are strings; extract the precision part\n",
    "    lat_precision = len(latitude.split(\".\")[-1]) if \".\" in latitude else 0\n",
    "    long_precision = len(longitude.split(\".\")[-1]) if \".\" in longitude else 0\n",
    "    # Return the total precision as the sum of both\n",
    "    return lat_precision + long_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_name(name):\n",
    "    return re.sub(r\"[ \\-&]\", \"_\", name).replace(\"___\", \"_\").replace(\"__\",\"_\").lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ridership table\n",
    "columns_to_keep = [\"transit_timestamp\", \"station_complex_id\", \"fare_class_category\", \"ridership\"]\n",
    "original_ridership = pl.read_parquet(\"data/hist.parquet\", columns=columns_to_keep, low_memory=True)\n",
    "\n",
    "ridership_wide = original_ridership.with_columns(\n",
    "    [pl.col(\"transit_timestamp\").str.strptime(pl.Datetime, format=\"%m/%d/%Y %I:%M:%S %p\"),\n",
    "     pl.col(\"ridership\").cast(pl.Int16)]\n",
    ").pivot(\n",
    "    index=[\"transit_timestamp\", \"station_complex_id\"],\n",
    "    columns=\"fare_class_category\",\n",
    "    values=\"ridership\",\n",
    "    aggregate_function=\"sum\",\n",
    "    sort_columns=True\n",
    ").sort(\n",
    "    [\"transit_timestamp\", \"station_complex_id\"], descending=[False, False]\n",
    ").fill_null(0)\n",
    "\n",
    "metrocard_columns = [col for col in ridership_wide.columns if \"Metrocard\" in col]\n",
    "omny_columns = [col for col in ridership_wide.columns if \"OMNY\" in col]\n",
    "ridership_columns = [col for col in ridership_wide.columns if \"Metrocard\" in col or \"OMNY\" in col]\n",
    "\n",
    "ridership = ridership_wide.with_columns(\n",
    "    total_metrocard_ridership=pl.sum_horizontal(col for col in metrocard_columns),\n",
    "    total_omny_ridership=pl.sum_horizontal(col for col in omny_columns),\n",
    "    total_ridership=pl.sum_horizontal(col for col in ridership_columns),\n",
    ")\n",
    "\n",
    "rename_mapping = {col: clean_column_name(col) for col in ridership.columns}\n",
    "ridership = ridership.rename(rename_mapping)\n",
    "\n",
    "#Since we got rid of the shuttle and TRAM lines, we filter them out here too.\n",
    "ridership = ridership.filter(~pl.col(\"station_complex_id\").str.contains(\"TRAM\")).filter(~pl.col(\"station_complex_id\").str.contains(\"141\"))\n",
    "ridership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Subset of the data for the other tables in the schema\n",
    "df = pl.read_parquet(\"data/hist.parquet\", n_rows=30_000_000, low_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stations table\n",
    "stations = df.select([\"station_complex_id\", \"station_complex\", \"borough\", \"latitude\", \"longitude\"]).unique()\n",
    "\n",
    "df_with_precision = stations.with_columns(\n",
    "    [(pl.struct([\"latitude\", \"longitude\"]).map_batches(\n",
    "        lambda batch: batch.map_elements(add_dec_prec, return_dtype=pl.Int64)\n",
    "    )).alias(\"total_precision\"),\n",
    "     pl.col(\"latitude\").cast(pl.Float64),\n",
    "     pl.col(\"longitude\").cast(pl.Float64)]\n",
    ")\n",
    "df_with_precision = df_with_precision.sort(['station_complex_id', 'total_precision'], descending=[False, True]).unique(subset=[\"station_complex_id\"])\n",
    "\n",
    "stations = df_with_precision.select([\"station_complex_id\", \"station_complex\", \"borough\", \"latitude\", \"longitude\"]).unique().sort(\"station_complex_id\")\n",
    "\n",
    "stations = stations.with_columns(\n",
    "    pl.col(\"station_complex\")\n",
    "    .str.replace_all(r\"\\,S\", \"\")\n",
    "    .str.replace_all(r\"\\(110 St\\)\", \"- 110 St\")\n",
    "    .str.replace_all(r\"\\/Botanic Garden \\(S\\)\", \"\")\n",
    "    .str.strip_chars()\n",
    "    ).filter(~pl.col(\"station_complex_id\").str.contains(\"TRAM\")\n",
    "    ).filter(~pl.col(\"station_complex\").str.contains(r\"\\(S\\)\")\n",
    "    ).sort(\"station_complex_id\")\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stations[\"station_complex\"].to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_clean = stations.with_columns(pl.col(\"station_complex\").str.replace_all(r\"\\([^)]*\\)\", \"\").str.strip_chars())\n",
    "stations_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Routes table\n",
    "station_list = stations[\"station_complex\"].to_list()\n",
    "regex_pattern = r\"\\(([^)]+)\\)\"\n",
    "\n",
    "unique_train_lines = set()\n",
    "\n",
    "for station in station_list:\n",
    "    matches = re.findall(regex_pattern, station)\n",
    "    if matches:\n",
    "        for line in matches[0].split(','):\n",
    "            unique_train_lines.add(line.strip())\n",
    "\n",
    "\n",
    "routes = pl.DataFrame({\n",
    "    \"route_name\": sorted(list(unique_train_lines))\n",
    "})\n",
    "routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Station_routes table\n",
    "station_routes = stations.with_columns(\n",
    "    pl.col(\"station_complex\")\n",
    "    .str.extract_all(r\"\\((.*?)\\)\")\n",
    "    .map_elements(lambda groups: ','.join(groups), return_dtype=str)\n",
    "    .str.replace_all(r\"\\(\", \"\")\n",
    "    .str.replace_all(r\"\\)\", \"\")\n",
    "    .str.split(\",\")\n",
    "    .alias(\"route_list\")\n",
    "    )\n",
    "\n",
    "# Step 3: Explode the list into separate rows\n",
    "stations_exploded = station_routes.explode(\"route_list\")\n",
    "\n",
    "# Step 4: Select and rename columns to fit the SQL schema, remove duplicates\n",
    "station_routes = stations_exploded.select([\n",
    "    pl.col(\"station_complex_id\"),\n",
    "    pl.col(\"station_complex\")\n",
    "    .str.replace_all(r\"\\([^)]*\\)\", \"\").str.strip_chars().alias(\"station_complex_unclean\"),\n",
    "    pl.col(\"route_list\").alias(\"route_name\")\n",
    "]).unique()\n",
    "\n",
    "station_routes = station_routes.sort(\"station_complex_id\")\n",
    "station_routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
